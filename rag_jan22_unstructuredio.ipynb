{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7HHJJGmkOdDY29FXx4r8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravz7/RAG/blob/main/rag_jan22_unstructuredio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxXX_B_dw7Po"
      },
      "outputs": [],
      "source": [
        "## Install Dependencies\n",
        "!pip3 install google-cloud-aiplatform langchain nbformat faiss-cpu --quiet\n",
        "!pip3 install tiktoken --quiet\n",
        "!pip3 install --upgrade openai --quiet\n",
        "!pip3 install cohere  --quiet\n",
        "\n",
        "#Authenticate the User\n",
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#General Imports\n",
        "import os, time, csv, re, json, requests, urllib\n",
        "from datetime import datetime\n",
        "\n",
        "#Import OpenAI, Cohere, GCP\n",
        "#from openai import OpenAI\n",
        "\n",
        "# LangChain\n",
        "# Models\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.llms import Cohere\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.memory import SimpleMemory\n",
        "\n",
        "# Vertex AI\n",
        "from google.cloud import aiplatform\n",
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel, TextEmbeddingModel\n",
        "\n",
        "# init the project which you want to use\n",
        "project_name = \"disttrain\"\n",
        "location = \"us-central1\"\n",
        "vertexai.init(project=project_name, location=location)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYqpGR5FxEBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClUJG6iDxEYV",
        "outputId": "712b69b4-85ea-40a3-a4d6-3c3ccf9feba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install llama-index --quiet\n",
        "from llama_index.llama_pack import download_llama_pack\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "EmbeddedTablesUnstructuredRetrieverPack = download_llama_pack(\n",
        "    \"EmbeddedTablesUnstructuredRetrieverPack\",\n",
        "    \"./embedded_tables_unstructured_pack\",\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dZsq6UKoxGQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/pdf2htmlEX/pdf2htmlEX/releases/download/v0.18.8.rc1/pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb\n",
        "!sudo apt install \"./pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb\" -y\n",
        "import subprocess\n",
        "\n",
        "def convert_pdf_to_html(pdf_path, html_path):\n",
        "    command = f\"pdf2htmlEX {pdf_path} --dest-dir {html_path}\"\n",
        "    subprocess.call(command, shell=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZM5BcmnxLKc",
        "outputId": "f7557523-eaec-4aab-ae3e-5640d21332f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-22 06:06:12--  https://github.com/pdf2htmlEX/pdf2htmlEX/releases/download/v0.18.8.rc1/pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/118475451/4ae63000-bae8-11ea-9475-e35496c41b6e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240122T060612Z&X-Amz-Expires=300&X-Amz-Signature=5d68255a92b138c37772c9189ff2b30652bfa11e9b1b7e1350cc456904e8b994&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=118475451&response-content-disposition=attachment%3B%20filename%3Dpdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-01-22 06:06:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/118475451/4ae63000-bae8-11ea-9475-e35496c41b6e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240122T060612Z&X-Amz-Expires=300&X-Amz-Signature=5d68255a92b138c37772c9189ff2b30652bfa11e9b1b7e1350cc456904e8b994&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=118475451&response-content-disposition=attachment%3B%20filename%3Dpdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4561732 (4.3M) [application/octet-stream]\n",
            "Saving to: ‘pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb’\n",
            "\n",
            "pdf2htmlEX-0.18.8.r 100%[===================>]   4.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-01-22 06:06:12 (45.3 MB/s) - ‘pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb’ saved [4561732/4561732]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'pdf2htmlex' instead of './pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb'\n",
            "The following NEW packages will be installed:\n",
            "  pdf2htmlex\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 0 B/4,562 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 /content/pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb pdf2htmlex amd64 0:0.0.18.8.rc1.master.bionic.20200630-0 [4,562 kB]\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pdf2htmlex.\n",
            "(Reading database ... 121658 files and directories currently installed.)\n",
            "Preparing to unpack .../pdf2htmlEX-0.18.8.rc1-master-20200630-Ubuntu-bionic-x86_64.deb ...\n",
            "Unpacking pdf2htmlex (0.0.18.8.rc1.master.bionic.20200630-0) ...\n",
            "Setting up pdf2htmlex (0.0.18.8.rc1.master.bionic.20200630-0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_pdf_to_html(\"Geminipaper.pdf\", \"Geminipaper\")\n",
        "convert_pdf_to_html(\"Alphabet_10K.pdf\", \"Alphabet_10K\")\n",
        "convert_pdf_to_html(\"Sample2.pdf\", \"Sample2\")"
      ],
      "metadata": {
        "id": "GcuqXI1ExNmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "from llama_index.readers.file.flat_reader import FlatReader\n",
        "from pathlib import Path\n",
        "from llama_index.node_parser import (\n",
        "    UnstructuredElementNodeParser,\n",
        ")\n",
        "\n",
        "node_parser = UnstructuredElementNodeParser()\n",
        "reader = FlatReader()\n",
        "\n",
        "\n",
        "def file_to_model(file_path, model_path):\n",
        "  pdf_file = reader.load_data(Path(file_path))\n",
        "  nodes = node_parser.get_nodes_from_documents(pdf_file)\n",
        "  pickle.dump(nodes, open(\"paper_nodes.pkl\", \"wb\"))\n",
        "  base_nodes, node_mappings = node_parser.get_base_nodes_and_mappings(\n",
        "    nodes)\n",
        "  return nodes, base_nodes, node_mappings\n",
        "\n"
      ],
      "metadata": {
        "id": "LV72i1qwxPtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filepath = \"Geminipaper/Geminipaper.html\"\n",
        "save_path = \"Geminipaper/Geminipaper.pkl\"\n",
        "\n",
        "nodes, base_nodes, node_mappings = file_to_model(filepath, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3nbWG13xUHi",
        "outputId": "64e2c654-122c-4ec6-ebb7-5c0b71ffd7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmFMD10Jxg8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Index\n",
        "\n",
        "# import chromadb/\n"
      ],
      "metadata": {
        "id": "MaLf_SHyxo3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "!pip install chromadb --quiet\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.vector_stores import ChromaVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from llama_index.embeddings import HuggingFaceEmbedding\n",
        "from IPython.display import Markdown, display\n",
        "import chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJJMLu8qxq2K",
        "outputId": "62cdc568-f396-485f-9d57-e3984b8070b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chroma_client = chromadb.EphemeralClient()\n",
        "#chroma_collection = chroma_client.create_collection(\"quickstart\")\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from llama_index.embeddings import GooglePaLMEmbedding\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "iter = 0\n",
        "doc_list = []\n",
        "\n",
        "for items in base_nodes:\n",
        "  iter += 1\n",
        "  new_doc =  Document(\n",
        "      page_content=items.text,\n",
        "      metadata={\n",
        "          \"source\": \"GeminiPaper\",\n",
        "          \"page\": iter\n",
        "      }\n",
        "  )\n",
        "  doc_list.append(new_doc)"
      ],
      "metadata": {
        "id": "uCbTb0wlxupd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(doc_list))\n",
        "doc_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8fDmlFyxyh8",
        "outputId": "889dd2b1-000a-4430-cf61-b088714037d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='2023-12-06\\n\\nGemini:\\n\\namily\\n\\nHighly\\n\\nCa\\n\\npab\\n\\nMultim\\n\\noda\\n\\nModels\\n\\nGemini\\n\\neam,\\n\\nGoogle\\n\\nThis\\n\\nreport\\n\\nintrod\\n\\nuces\\n\\nnew\\n\\nfamily\\n\\nof\\n\\nultimodal\\n\\nmodels,\\n\\nGemini,\\n\\nthat\\n\\nexhibit\\n\\nremarkab\\n\\nle\\n\\ncapabiliti\\n\\nes\\n\\nacross\\n\\nimage,\\n\\naudio,\\n\\nvideo,\\n\\nand\\n\\ntext\\n\\nunderstanding.\\n\\nThe\\n\\nGemini\\n\\nfamily\\n\\nconsists\\n\\nof\\n\\nUltra,\\n\\nPro,\\n\\nand\\n\\nNano\\n\\nsizes,\\n\\nsuit\\n\\nab\\n\\nle\\n\\nfor\\n\\napplicati\\n\\nons\\n\\nranging\\n\\nfrom\\n\\ncomplex\\n\\nrea\\n\\nsoning\\n\\nas\\n\\nks\\n\\nto\\n\\non-device\\n\\nmem\\n\\nory-constrained\\n\\nuse-cases.\\n\\nEvaluati\\n\\non\\n\\non\\n\\nbroad\\n\\nrange\\n\\nof\\n\\nbenchmarks\\n\\nho\\n\\nthat\\n\\nour\\n\\nmost-ca\\n\\npab\\n\\nle\\n\\nGemini\\n\\nUltra\\n\\nmodel\\n\\nadvances\\n\\nthe\\n\\nstate-of\\n\\nthe-art\\n\\nin\\n\\n30\\n\\nof\\n\\n32\\n\\nof\\n\\nthese\\n\\nbenchmarks\\n\\nnotably\\n\\nbeing\\n\\nthe\\n\\nﬁrst\\n\\nmodel\\n\\nto\\n\\nachiev\\n\\nhuman-expert\\n\\nperforman\\n\\nce\\n\\non\\n\\nthe\\n\\nwell-studi\\n\\ned\\n\\nexam\\n\\nbenchmark\\n\\nMMLU,\\n\\nand\\n\\nimproving\\n\\nthe\\n\\nst\\n\\nate\\n\\nof\\n\\nthe\\n\\nart\\n\\nin\\n\\nev\\n\\nery\\n\\non\\n\\nthe\\n\\n20\\n\\nultim\\n\\nodal\\n\\nbenchmarks\\n\\nexamined.\\n\\nbelieve\\n\\nthat\\n\\nthe\\n\\nnew\\n\\ncapa\\n\\nbilities\\n\\nof\\n\\nGemini\\n\\nodels\\n\\nin\\n\\ncross-m\\n\\nodal\\n\\nreasoning\\n\\nand\\n\\nanguage\\n\\nunderstanding\\n\\nwill\\n\\nenabl\\n\\nwide\\n\\nvariet\\n\\nuse\\n\\ncases\\n\\nand\\n\\nwe\\n\\ndiscuss\\n\\nour\\n\\napproach\\n\\nto\\n\\nward\\n\\ndeploying\\n\\nthem\\n\\nrespo\\n\\nnsibly\\n\\nto\\n\\nusers.\\n\\n1.\\n\\nIntrod\\n\\nuctio\\n\\npresent\\n\\nGemini,\\n\\namily\\n\\nof\\n\\nhighly\\n\\ncapa\\n\\nble\\n\\nmultim\\n\\nodal\\n\\nmodels\\n\\ndeveloped\\n\\nat\\n\\nGoogle.\\n\\ntrained\\n\\nGemini\\n\\njointly\\n\\nacross\\n\\nimage,\\n\\naudio,\\n\\nvideo,\\n\\nand\\n\\ntext\\n\\ndata\\n\\nfor\\n\\nthe\\n\\npurpose\\n\\nof\\n\\nuilding\\n\\nodel\\n\\nwith\\n\\nboth\\n\\nstrong\\n\\ngenera\\n\\nlist\\n\\ncapa\\n\\nbilities\\n\\nacross\\n\\nmoda\\n\\nlities\\n\\nalo\\n\\nngside\\n\\ncutting-edge\\n\\nunderst\\n\\nanding\\n\\nand\\n\\nreasoning\\n\\nperforman\\n\\nce\\n\\nin\\n\\neach\\n\\nrespectiv\\n\\ndomain.\\n\\nGemini\\n\\n1.0,\\n\\nur\\n\\nﬁrst\\n\\nersio\\n\\nn,\\n\\ncomes\\n\\nin\\n\\nthree\\n\\nsizes:\\n\\nUltra\\n\\nor\\n\\nhighly-complex\\n\\nsks,\\n\\nPro\\n\\nfor\\n\\nenhanced\\n\\nperforman\\n\\nce\\n\\nand\\n\\ndeployability\\n\\nat\\n\\nscale,\\n\\nand\\n\\nNan\\n\\nfor\\n\\non-devi\\n\\nce\\n\\napplicati\\n\\nons.\\n\\nEach\\n\\nsi\\n\\nze\\n\\nis\\n\\nspeciﬁ\\n\\ncally\\n\\ntailored\\n\\nto\\n\\naddress\\n\\ndiﬀerent\\n\\ncomputationa\\n\\nlimitations\\n\\nand\\n\\napplicati\\n\\non\\n\\nrequirements.\\n\\nevaluate\\n\\nthe\\n\\nperforman\\n\\nce\\n\\nof\\n\\nGemini\\n\\nodels\\n\\non\\n\\ncomprehensiv\\n\\nsuite\\n\\nof\\n\\ninternal\\n\\nand\\n\\nextern\\n\\nal\\n\\nbenchmarks\\n\\nco\\n\\nering\\n\\nwide\\n\\nrange\\n\\nlanguage,\\n\\ncoding,\\n\\nrea\\n\\nsoning,\\n\\nand\\n\\nultim\\n\\nodal\\n\\nasks.\\n\\nGemini\\n\\nadvances\\n\\nst\\n\\nate-of\\n\\nthe-art\\n\\nin\\n\\nlarge-scale\\n\\nanguage\\n\\nmodeling\\n\\nAnil et al.,\\n\\n2023;\\n\\nBrown et al.,\\n\\n2020\\n\\n; Cho\\n\\nwd\\n\\nhery\\n\\net\\n\\nal.\\n\\n, 2023\\n\\n; Ho\\n\\nﬀmann\\n\\net\\n\\nal.\\n\\n, 2022\\n\\n; OpenAI\\n\\n, 2023a\\n\\n; Radford\\n\\net\\n\\nal.\\n\\n, 2019\\n\\n; Rae\\n\\net\\n\\nal.\\n\\n, 2021\\n\\n), image understanding (Al\\n\\nyrac\\n\\net\\n\\nal.\\n\\n, 2022\\n\\n; Chen\\n\\net\\n\\nal.\\n\\n, 2022\\n\\n; K\\n\\nolesniko\\n\\net\\n\\nl.\\n\\n, 2021\\n\\nOpenAI\\n\\n, 2023b\\n\\n; R\\n\\need\\n\\net\\n\\nal.\\n\\n, 2022\\n\\n; Y\\n\\net\\n\\nal.\\n\\n, 2022a\\n\\n), audio processing (Radford\\n\\net\\n\\nl.\\n\\n, 2023\\n\\n; Z\\n\\nhang\\n\\net\\n\\nal.\\n\\n, 2023\\n\\n), and video understanding(Al\\n\\nyrac\\n\\net\\n\\nal.\\n\\n, 2022\\n\\n; Chen\\n\\net\\n\\nl.\\n\\n, 2023\\n\\n).', metadata={'source': 'GeminiPaper', 'page': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "!pip install -U langchain-google-genai\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "os.environ[\"GOOGLE_API_KEY\"]=\"AIzaSyDU99XlPxtwQX69NrxXj3h8kYm8Detgqrw\"\n",
        "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/textembedding-gecko@001\")\n",
        "#embeddings = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
        "# use directly\n",
        "#palm_api_key = \"AIzaSyDU99XlPxtwQX69NrxXj3h8kYm8Detgqrw\"\n",
        "#google_ef  = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=palm_api_key)\n",
        "\n",
        "\n",
        "#from langchain.indexes import VectorstoreIndexCreator\n",
        "#db = Chroma.from_documents(doc_list, embeddings, collection_name=\"gcp_basic_collection\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tiEVTE_x3Yi",
        "outputId": "227aee66-9f61-4541-da45-15a8e1d4892f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-0.0.6-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.1.13)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.0.84,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (0.0.83)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (8.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2023.11.17)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.5.1)\n",
            "Installing collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "openai_api_key=\"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\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "embeddings_openai = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "#db = Chroma.from_documents(doc_list, embeddings, collection_name=\"gcp_collection\")\n",
        "\n",
        "db = Chroma.from_documents(doc_list, embeddings_openai, collection_name=\"openai_basic_collection\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTpfRSS4x8lC",
        "outputId": "53c6fb6d-f76e-4a49-984a-5ae8685b9aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Whats Gemini ultra?\"\n",
        "docs = db.similarity_search(query)\n",
        "print (docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEW_ycoCyYvH",
        "outputId": "bb325bbd-be14-4678-d1b4-40ffee236d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini\n",
            "\n",
            "Ultra\n",
            "\n",
            "achiev\n",
            "\n",
            "es\n",
            "\n",
            "st\n",
            "\n",
            "ate-of\n",
            "\n",
            "the-art\n",
            "\n",
            "results\n",
            "\n",
            "on\n",
            "\n",
            "vari\n",
            "\n",
            "ous\n",
            "\n",
            "few-shot\n",
            "\n",
            "video\n",
            "\n",
            "capti\n",
            "\n",
            "oning\n",
            "\n",
            "sks\n",
            "\n",
            "as\n",
            "\n",
            "ell\n",
            "\n",
            "as\n",
            "\n",
            "zero-shot\n",
            "\n",
            "video\n",
            "\n",
            "questi\n",
            "\n",
            "on\n",
            "\n",
            "answering\n",
            "\n",
            "tasks\n",
            "\n",
            "as\n",
            "\n",
            "sho\n",
            "\n",
            "wn\n",
            "\n",
            "in\n",
            "\n",
            "ble\n",
            "\n",
            "10.\n",
            "\n",
            "This\n",
            "\n",
            "demo\n",
            "\n",
            "nstrates\n",
            "\n",
            "its\n",
            "\n",
            "capa\n",
            "\n",
            "bilit\n",
            "\n",
            "strong\n",
            "\n",
            "tempora\n",
            "\n",
            "reaso\n",
            "\n",
            "ning\n",
            "\n",
            "across\n",
            "\n",
            "sev\n",
            "\n",
            "eral\n",
            "\n",
            "frames.\n",
            "\n",
            "Figure\n",
            "\n",
            "21 in\n",
            "\n",
            "the\n",
            "\n",
            "appendix\n",
            "\n",
            "pro\n",
            "\n",
            "vides\n",
            "\n",
            "an\n",
            "\n",
            "example\n",
            "\n",
            "understanding\n",
            "\n",
            "the\n",
            "\n",
            "video\n",
            "\n",
            "the\n",
            "\n",
            "ball-striking\n",
            "\n",
            "mechanics\n",
            "\n",
            "of\n",
            "\n",
            "soccer\n",
            "\n",
            "player\n",
            "\n",
            "and\n",
            "\n",
            "reasoning\n",
            "\n",
            "about\n",
            "\n",
            "they\n",
            "\n",
            "can\n",
            "\n",
            "improv\n",
            "\n",
            "it.\n",
            "\n",
            "ask\n",
            "\n",
            "Gemini\n",
            "\n",
            "Ultra\n",
            "\n",
            "Gemini\n",
            "\n",
            "Pro\n",
            "\n",
            "ew-shot\n",
            "\n",
            "SoT\n",
            "\n",
            "TEX\n",
            "\n",
            "(test)\n",
            "\n",
            "62.7\n",
            "\n",
            "57.4 56.0\n",
            "\n",
            "English\n",
            "\n",
            "video\n",
            "\n",
            "captioning\n",
            "\n",
            "Wang et al., 2019)\n",
            "\n",
            "4-shots\n",
            "\n",
            "4-shots\n",
            "\n",
            "DeepMind\n",
            "\n",
            "Fl\n",
            "\n",
            "amingo,\n",
            "\n",
            "4-shots\n",
            "\n",
            "TEX\n",
            "\n",
            "ZH\n",
            "\n",
            "(test)\n",
            "\n",
            "51.3\n",
            "\n",
            "50.0 –\n",
            "\n",
            "Chinese\n",
            "\n",
            "video\n",
            "\n",
            "captioning\n",
            "\n",
            "Wang et al., 2019)\n",
            "\n",
            "4-shots\n",
            "\n",
            "4-shots\n",
            "\n",
            "ouCook2\n",
            "\n",
            "val)\n",
            "\n",
            "135.4\n",
            "\n",
            "123.2 74.5\n",
            "\n",
            "English\n",
            "\n",
            "cooking\n",
            "\n",
            "video\n",
            "\n",
            "captio\n",
            "\n",
            "ning\n",
            "\n",
            "Zhou et al.,\n",
            "\n",
            "2018)\n",
            "\n",
            "4-shots\n",
            "\n",
            "4-shots\n",
            "\n",
            "DeepMind\n",
            "\n",
            "Fl\n",
            "\n",
            "amingo,\n",
            "\n",
            "4-shots\n",
            "\n",
            "NextQ\n",
            "\n",
            "(test)\n",
            "\n",
            "29.9\n",
            "\n",
            "28.0 26.7\n",
            "\n",
            "Video\n",
            "\n",
            "question\n",
            "\n",
            "answering\n",
            "\n",
            "Xiao et al.,\n",
            "\n",
            "2021)\n",
            "\n",
            "0-shot\n",
            "\n",
            "0-shot\n",
            "\n",
            "DeepMind\n",
            "\n",
            "Fl\n",
            "\n",
            "amingo,\n",
            "\n",
            "0-shot\n",
            "\n",
            "Activit\n",
            "\n",
            "yNet-Q\n",
            "\n",
            "(test)\n",
            "\n",
            "52.2\n",
            "\n",
            "49.8 45.3\n",
            "\n",
            "Video\n",
            "\n",
            "question\n",
            "\n",
            "answering\n",
            "\n",
            "Yu et al.,\n",
            "\n",
            "2019)\n",
            "\n",
            "0-shot\n",
            "\n",
            "0-shot\n",
            "\n",
            "Video-LLA\n",
            "\n",
            "A,\n",
            "\n",
            "0-shot\n",
            "\n",
            "Percepti\n",
            "\n",
            "on\n",
            "\n",
            "est\n",
            "\n",
            "MCQA\n",
            "\n",
            "(test)\n",
            "\n",
            "54.7\n",
            "\n",
            "51.1 46.3\n",
            "\n",
            "Video\n",
            "\n",
            "question\n",
            "\n",
            "answering\n",
            "\n",
            "Pătrăucean et al.,\n",
            "\n",
            "2023)\n",
            "\n",
            "0-shot\n",
            "\n",
            "0-shot\n",
            "\n",
            "SeViLA\n",
            "\n",
            "Yu et al.,\n",
            "\n",
            "2023),\n",
            "\n",
            "0-shot\n",
            "\n",
            "ab\n",
            "\n",
            "le\n",
            "\n",
            "10\n",
            "\n",
            "ew-s\n",
            "\n",
            "hot\n",
            "\n",
            "video\n",
            "\n",
            "underst\n",
            "\n",
            "anding\n",
            "\n",
            "across\n",
            "\n",
            "as\n",
            "\n",
            "ks\n",
            "\n",
            "and\n",
            "\n",
            "anguages\n",
            "\n",
            ", on selected academic\n",
            "\n",
            "benchmarks.\n",
            "\n",
            "The\n",
            "\n",
            "reported\n",
            "\n",
            "metrics\n",
            "\n",
            "for\n",
            "\n",
            "video\n",
            "\n",
            "captio\n",
            "\n",
            "ning\n",
            "\n",
            "is\n",
            "\n",
            "CI\n",
            "\n",
            "ER,\n",
            "\n",
            "UPS\n",
            "\n",
            "or\n",
            "\n",
            "NextQ\n",
            "\n",
            "A,\n",
            "\n",
            "top-1\n",
            "\n",
            "accuracy\n",
            "\n",
            "for\n",
            "\n",
            "the\n",
            "\n",
            "Percepti\n",
            "\n",
            "on\n",
            "\n",
            "est\n",
            "\n",
            "and\n",
            "\n",
            "for\n",
            "\n",
            "Activit\n",
            "\n",
            "yNet-Q\n",
            "\n",
            "A,\n",
            "\n",
            "the\n",
            "\n",
            "Video-LLA\n",
            "\n",
            "Lin et al., 2023) evaluation protocol.\n",
            "\n",
            "5.2.3.\n",
            "\n",
            "Image\n",
            "\n",
            "Generati\n",
            "\n",
            "on\n",
            "\n",
            "Gemini\n",
            "\n",
            "is\n",
            "\n",
            "le\n",
            "\n",
            "to\n",
            "\n",
            "output\n",
            "\n",
            "images\n",
            "\n",
            "nativ\n",
            "\n",
            "ely\n",
            "\n",
            "without\n",
            "\n",
            "ha\n",
            "\n",
            "ving\n",
            "\n",
            "to\n",
            "\n",
            "rely\n",
            "\n",
            "on\n",
            "\n",
            "an\n",
            "\n",
            "intermediate\n",
            "\n",
            "natural\n",
            "\n",
            "langu\n",
            "\n",
            "age\n",
            "\n",
            "descriptio\n",
            "\n",
            "that\n",
            "\n",
            "can\n",
            "\n",
            "bottleneck\n",
            "\n",
            "the\n",
            "\n",
            "odel’s\n",
            "\n",
            "abilit\n",
            "\n",
            "to\n",
            "\n",
            "express\n",
            "\n",
            "images.\n",
            "\n",
            "This\n",
            "\n",
            "uniquely\n",
            "\n",
            "enab\n",
            "\n",
            "les\n",
            "\n",
            "the\n",
            "\n",
            "odel\n",
            "\n",
            "to\n",
            "\n",
            "generate\n",
            "\n",
            "images\n",
            "\n",
            "with\n",
            "\n",
            "prompts\n",
            "\n",
            "using\n",
            "\n",
            "interleav\n",
            "\n",
            "ed\n",
            "\n",
            "sequences\n",
            "\n",
            "image\n",
            "\n",
            "and\n",
            "\n",
            "text\n",
            "\n",
            "in\n",
            "\n",
            "few-shot\n",
            "\n",
            "setting.\n",
            "\n",
            "or\n",
            "\n",
            "example,\n",
            "\n",
            "the\n",
            "\n",
            "user\n",
            "\n",
            "might\n",
            "\n",
            "prompt\n",
            "\n",
            "the\n",
            "\n",
            "model\n",
            "\n",
            "to\n",
            "\n",
            "design\n",
            "\n",
            "suggestions\n",
            "\n",
            "of\n",
            "\n",
            "images\n",
            "\n",
            "and\n",
            "\n",
            "text\n",
            "\n",
            "or\n",
            "\n",
            "bl\n",
            "\n",
            "og\n",
            "\n",
            "post\n",
            "\n",
            "or\n",
            "\n",
            "website\n",
            "\n",
            "(see\n",
            "\n",
            "Figure\n",
            "\n",
            "10 in\n",
            "\n",
            "the\n",
            "\n",
            "appendix).\n",
            "\n",
            "15\n",
            "\n",
            "Gemini:\n",
            "\n",
            "amily\n",
            "\n",
            "of\n",
            "\n",
            "Highly\n",
            "\n",
            "Capa\n",
            "\n",
            "bl\n",
            "\n",
            "Multimodal\n",
            "\n",
            "Models\n",
            "\n",
            "Figure\n",
            "\n",
            "6 sho\n",
            "\n",
            "ws\n",
            "\n",
            "an\n",
            "\n",
            "example\n",
            "\n",
            "of\n",
            "\n",
            "image\n",
            "\n",
            "generatio\n",
            "\n",
            "in\n",
            "\n",
            "1-shot\n",
            "\n",
            "setting.\n",
            "\n",
            "Gemini\n",
            "\n",
            "Ultra\n",
            "\n",
            "model\n",
            "\n",
            "is\n",
            "\n",
            "prompted\n",
            "\n",
            "with\n",
            "\n",
            "on\n",
            "\n",
            "example\n",
            "\n",
            "interleav\n",
            "\n",
            "ed\n",
            "\n",
            "image\n",
            "\n",
            "and\n",
            "\n",
            "text\n",
            "\n",
            "where\n",
            "\n",
            "the\n",
            "\n",
            "user\n",
            "\n",
            "provides\n",
            "\n",
            "colors\n",
            "\n",
            "(blue\n",
            "\n",
            "and\n",
            "\n",
            "yellow)\n",
            "\n",
            "and\n",
            "\n",
            "image\n",
            "\n",
            "suggestions\n",
            "\n",
            "of\n",
            "\n",
            "creating\n",
            "\n",
            "cute\n",
            "\n",
            "blue\n",
            "\n",
            "cat\n",
            "\n",
            "or\n",
            "\n",
            "lue\n",
            "\n",
            "dog\n",
            "\n",
            "with\n",
            "\n",
            "yello\n",
            "\n",
            "ear\n",
            "\n",
            "from\n",
            "\n",
            "yarn.\n",
            "\n",
            "The\n",
            "\n",
            "odel\n",
            "\n",
            "is\n",
            "\n",
            "then\n",
            "\n",
            "given\n",
            "\n",
            "new\n",
            "\n",
            "colors\n",
            "\n",
            "pink\n",
            "\n",
            "and\n",
            "\n",
            "green)\n",
            "\n",
            "and\n",
            "\n",
            "asked\n",
            "\n",
            "for\n",
            "\n",
            "idea\n",
            "\n",
            "abo\n",
            "\n",
            "ut\n",
            "\n",
            "what\n",
            "\n",
            "to\n",
            "\n",
            "create\n",
            "\n",
            "using\n",
            "\n",
            "these\n",
            "\n",
            "colors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdympqdUysDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup retriver"
      ],
      "metadata": {
        "id": "HocXAJERysjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER_OF_RESULTS = 1\n",
        "SEARCH_DISTANCE_THRESHOLD = 0.8\n",
        "\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": NUMBER_OF_RESULTS\n",
        "        #\"score_threshold\": SEARCH_DISTANCE_THRESHOLD\n",
        "    },\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "DFNZhMBoycfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import VertexAI\n",
        "from langchain_community.llms import Cohere\n",
        "openai_api_key=\"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\"\n",
        "cohere_key = \"pXEsGG3TIOR2YdoCzlpXFNbZF1Ui3UqcwdaYHrVD\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "os.environ[\"COHERE_API_KEY\"] = cohere_key\n",
        "# Uses LLM to synthesize results from the search index.\n",
        "# We use Vertex PaLM Text API for LLM\n",
        "# Uses LLM to synthesize results from the search index.\n",
        "# Use Vertex PaLM Text API for LLM\n",
        "\n",
        "template = \"\"\"SYSTEM: You are an intelligent assistant\n",
        "\n",
        "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
        "\n",
        "Do not try to make up an answer:\n",
        " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
        " - If the context is empty, just say \"I do not know the answer to that.\"\n",
        "\n",
        "=============\n",
        "{context}\n",
        "=============\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "# Text model instance integrated with langChain\n",
        "from openai import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "#!pip install -U --quiet langchain-google-genai pillow==10.0.0\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from vertexai.preview.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Image,\n",
        "    Part,\n",
        ")\n",
        "\n",
        "def ret_func(model):\n",
        "\n",
        "  if model == \"text-bison@002\":\n",
        "    llm = VertexAI(\n",
        "        model_name=\"text-bison@002\",\n",
        "        max_output_tokens=1024,\n",
        "        temperature=0,\n",
        "        top_p=0.8,\n",
        "        top_k=40)\n",
        "\n",
        "  if model == \"text-bison@001\":\n",
        "    llm = VertexAI(\n",
        "        model_name=\"text-bison@001\",\n",
        "        max_output_tokens=1024,\n",
        "        temperature=0,\n",
        "        top_p=0.8,\n",
        "        top_k=40)\n",
        "\n",
        "\n",
        "  if model ==\"text-unicorn@001\":\n",
        "    llm = VertexAI(\n",
        "      model_name=\"text-unicorn@001\",\n",
        "      max_output_tokens=1024,\n",
        "      temperature=0,\n",
        "      top_p=0.8,\n",
        "      top_k=40)\n",
        "\n",
        "  if model ==\"gemini-pro\":\n",
        "    #llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature=0)\n",
        "    llm = GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "\n",
        "  ## Model Garden models\n",
        "  #if model == \"llama-7b\":\n",
        "  #  llm = llm_llama\n",
        "  #if model == \"mistral-7b\":\n",
        "  #  llm = llm_mistral\n",
        "\n",
        "\n",
        "  ## Cohere models\n",
        "  #if model == \"command-nightly\":\n",
        "  #  llm = Cohere(model=\"command-nightly\")\n",
        "  #if model == \"command-light-nightly\":\n",
        "  #  llm = Cohere(model=\"command-light-nightly\")\n",
        "\n",
        "  # GPT Models\n",
        "  if model == \"gpt-4\":\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4\")\n",
        "  if model == \"gpt-3.5-turbo\":\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "  qa = RetrievalQA.from_chain_type(\n",
        "      llm=llm,\n",
        "      chain_type=\"stuff\",\n",
        "      retriever=retriever,\n",
        "      return_source_documents=True,\n",
        "      verbose=True,\n",
        "\n",
        "      chain_type_kwargs={\n",
        "          \"prompt\": PromptTemplate(\n",
        "              template=template,\n",
        "              input_variables=[\"context\", \"question\"],\n",
        "          ),\n",
        "      },\n",
        "  )\n",
        "\n",
        "  return qa, llm"
      ],
      "metadata": {
        "id": "pHFYyhfhyuZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_query = \"I am a senior manager, What's my notice period ?\"\n",
        "\n",
        "qabison,llm1 = ret_func(\"text-bison@002\")\n",
        "qaunicorn,llm2 = ret_func(\"text-unicorn@001\")\n",
        "#qa,llm3 = ret_func(\"gemini-pro\")\n",
        "#qa,llm3 = ret_func(\"mistral-7b\")\n",
        "\n",
        "context = \"\"\n",
        "prompt = template.format(question=test_query, context = context)\n",
        "response_gcp1 = llm1.predict(prompt)\n",
        "response_gcp2 = llm2.predict(prompt)\n",
        "#response_gcp3 = llm3.predict(prompt)\n",
        "\n",
        "print(\"Bison @ 002 \", response_gcp1)\n",
        "print(\"Unicorn @ 001 \",response_gcp2)\n",
        "#print(\"Mistral 7B \",response_gcp3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ie_abndy6uG",
        "outputId": "b0c86c5a-7e99-4525-9c4b-76a920382c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bison @ 002   I cannot determine the answer to that.\n",
            "Unicorn @ 001   The notice period for a senior manager is typically 3 months. However, this may vary depending on the company's policies. It is best to check your employment contract or with your HR department to confirm your notice period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation framework"
      ],
      "metadata": {
        "id": "0_oy1l7Tzq72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install ragas\n",
        "import ragas\n",
        "from ragas.metrics import faithfulness, answer_relevancy, context_relevancy, context_recall\n",
        "from ragas.langchain import RagasEvaluatorChain\n",
        "\n",
        "# make eval chains\n",
        "eval_chains = {\n",
        "    m.name: RagasEvaluatorChain(metric=m)\n",
        "    for m in [faithfulness, answer_relevancy, context_relevancy]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3q2w_9PzECi",
        "outputId": "edefb536-69c7-4665-99a2-36e6c8b02551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ragas in /usr/local/lib/python3.10/dist-packages (0.0.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ragas) (1.23.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from ragas) (2.16.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from ragas) (0.5.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from ragas) (0.1.1)\n",
            "Requirement already satisfied: openai>1 in /usr/local/lib/python3.10/dist-packages (from ragas) (1.9.0)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from ragas) (0.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas) (1.5.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>1->ragas) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (2.0.24)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (0.0.13)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (0.1.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (0.0.83)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (8.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain->ragas) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->ragas) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->ragas) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->ragas) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->ragas) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am a senior manager, What's my notice period ?\"\n",
        "\n",
        "query = \"What are number of parameters in Gemini Nano?\"\n",
        "\n",
        "query = \"Whats Gemini Ultra performance on MMLU benchmarks?\"\n",
        "\n",
        "result = qabison({\"query\": query})\n",
        "\n",
        "print(\"Result : \",result)\n",
        "\n",
        "for name, eval_chain in eval_chains.items():\n",
        "    score_name = f\"{name}_score\"\n",
        "    print(f\"{score_name}: {eval_chain(result)[score_name]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoBqxowHzh-c",
        "outputId": "024c1402-bedd-4ca1-f477-6ad37ec9db0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Result :  {'query': 'Whats Gemini Ultra performance on MMLU benchmarks?', 'result': ' On the MMLU benchmark, Gemini Ultra achieves an accuracy of 90.04%, outperforming all existing models.', 'source_documents': [Document(page_content='In\\n\\nthis\\n\\nsectio\\n\\nn,\\n\\nwe\\n\\nexamine\\n\\nsome\\n\\nof\\n\\nthese\\n\\nﬁndings.\\n\\nOn\\n\\nMMLU\\n\\nHendrycks et al.,\\n\\n2021a),\\n\\nGemini\\n\\nUltra\\n\\ncan\\n\\noutperf\\n\\norm\\n\\nall\\n\\nexisting\\n\\nodels,\\n\\nachieving\\n\\nan\\n\\naccuracy\\n\\nof\\n\\n90.04%.\\n\\nMMLU\\n\\nis\\n\\nholistic\\n\\nexam\\n\\nbenchmark,\\n\\nwhich\\n\\nmeasures\\n\\nkn\\n\\nwledge\\n\\nacross\\n\\nset\\n\\n57\\n\\nsubjects.\\n\\nHuman\\n\\nexpert\\n\\nperf\\n\\normance\\n\\nis\\n\\ngauged\\n\\nat\\n\\n89.8%\\n\\nby\\n\\nthe\\n\\nbenchmark\\n\\nauthors,\\n\\nand\\n\\nGemini\\n\\nUltra\\n\\nis\\n\\nthe\\n\\nﬁrst\\n\\nmodel\\n\\nto\\n\\nexceed\\n\\nthis\\n\\nthreshold,\\n\\nwith\\n\\nthe\\n\\nprior\\n\\nst\\n\\nate-o\\n\\nf-the-art\\n\\nresult\\n\\nat\\n\\n86.4%.\\n\\nAchieving\\n\\nhigh\\n\\nperformance\\n\\nrequires\\n\\nspecialist\\n\\nkno\\n\\nwledge\\n\\nacross\\n\\nmany\\n\\ndomains\\n\\ne.g.\\n\\nlaw\\n\\nbiol\\n\\nogy\\n\\nhistory\\n\\netc.),\\n\\nalo\\n\\nngside\\n\\nreading\\n\\ncomprehensio\\n\\nand\\n\\nreasoning.\\n\\nﬁnd\\n\\nGemini\\n\\nUltra\\n\\nachiev\\n\\nes\\n\\nhighest\\n\\naccuracy\\n\\nwhen\\n\\nused\\n\\nin\\n\\ncombinati\\n\\non\\n\\nwith\\n\\nchain-of\\n\\nthought\\n\\nprompting\\n\\napproach\\n\\nWei et al., 2022)\\n\\nthat\\n\\naccounts\\n\\nfor\\n\\nmodel\\n\\nuncertaint\\n\\nThe\\n\\nodel\\n\\nprodu\\n\\nces\\n\\nchain\\n\\nthought\\n\\nwith\\n\\nsamples,\\n\\nfor\\n\\nexample\\n\\nor\\n\\n32.\\n\\nIf\\n\\nthere\\n\\nis\\n\\nconsensus\\n\\nabo\\n\\nve\\n\\npreset\\n\\nthreshold\\n\\n(selected\\n\\nba\\n\\nsed\\n\\non\\n\\nthe\\n\\nva\\n\\nlidation\\n\\nsplit),\\n\\nit\\n\\nselects\\n\\nthis\\n\\nansw\\n\\ner\\n\\notherwise\\n\\nit\\n\\nrev\\n\\nerts\\n\\nto\\n\\ngreedy\\n\\nsample\\n\\nbased\\n\\non\\n\\nmaximum\\n\\nlikelihood\\n\\nchoi\\n\\nce\\n\\nwithout\\n\\nchain\\n\\nthought.\\n\\nrefer\\n\\nthe\\n\\nreader\\n\\nto\\n\\nappendix\\n\\nfor\\n\\ndet\\n\\nailed\\n\\nbreakdo\\n\\nwn\\n\\nhow\\n\\nthis\\n\\napproach\\n\\ncompares\\n\\nwith\\n\\nonly\\n\\nchain-o\\n\\nf-thought\\n\\nprompting\\n\\nor\\n\\nonly\\n\\ngreedy\\n\\nsampling.\\n\\nIn\\n\\nmathematics,\\n\\nﬁeld\\n\\ncomm\\n\\nonly\\n\\nused\\n\\nto\\n\\nbenchmark\\n\\nthe\\n\\nanalytica\\n\\ncapa\\n\\nbilities\\n\\nof\\n\\nodels,\\n\\nGemini\\n\\nUltra\\n\\nsho\\n\\nws\\n\\nstrong\\n\\nperformance\\n\\non\\n\\nboth\\n\\nelementary\\n\\nexams\\n\\nand\\n\\ncompetiti\\n\\non-grade\\n\\nproblem\\n\\nsets.\\n\\nor\\n\\nthe\\n\\ngrade-school\\n\\nmath\\n\\nbenchmark,\\n\\nGSM8K\\n\\nob\\n\\nbe\\n\\net\\n\\nal.\\n\\n, 2021\\n\\nﬁnd\\n\\nGemini\\n\\nUltra\\n\\nreaches\\n\\n94.4%\\n\\naccuracy\\n\\nwith\\n\\nchain-of\\n\\nthought\\n\\nprompting\\n\\nand\\n\\nself-consisten\\n\\ncy\\n\\nWang et al., 2022) compared to\\n\\nthe\\n\\nprevio\\n\\nus\\n\\nbest\\n\\naccuracy\\n\\n92%\\n\\nwith\\n\\nthe\\n\\nsame\\n\\nprompting\\n\\ntechniqu\\n\\ne.\\n\\nSimil\\n\\nar\\n\\npositiv\\n\\ntrends\\n\\nare\\n\\nobserv\\n\\ned\\n\\nin\\n\\nincreased\\n\\ndiﬃcult\\n\\nmath\\n\\nprob\\n\\nlems\\n\\ndrawn\\n\\nfrom\\n\\nmidd\\n\\nle-\\n\\nand\\n\\nhigh-school\\n\\nmath\\n\\ncompetitio\\n\\nns\\n\\n(MA\\n\\nTH\\n\\nbenchmark),\\n\\nwith\\n\\nthe\\n\\nGemini\\n\\nUltra\\n\\nodel\\n\\noutperf\\n\\norming\\n\\nall\\n\\ncompetitor\\n\\nodels,\\n\\nreaching\\n\\n53.2%\\n\\nusing\\n\\n4-shot\\n\\nprompting.\\n\\nThe\\n\\nmodel\\n\\nalso\\n\\noutperforms\\n\\nthe\\n\\nst\\n\\nate\\n\\nof\\n\\nthe\\n\\nart\\n\\non\\n\\neven\\n\\nharder\\n\\nsks\\n\\nderiv\\n\\ned\\n\\nfrom\\n\\nAmerican\\n\\nMathematica\\n\\nCompetiti\\n\\nons\\n\\n(150\\n\\nquestio\\n\\nns\\n\\nfrom\\n\\n2022\\n\\nand\\n\\n2023).\\n\\nSmaller\\n\\nodels\\n\\nperform\\n\\npoorly\\n\\non\\n\\nthis\\n\\nchallenging\\n\\nas\\n\\nscoring\\n\\nclose\\n\\nto\\n\\nrandom,\\n\\nbut\\n\\nGemini\\n\\nUltra\\n\\ncan\\n\\nsolve\\n\\n32%\\n\\nof\\n\\nthe\\n\\nquesti\\n\\nons,\\n\\ncompared\\n\\nto\\n\\nthe\\n\\n30%\\n\\nsolv\\n\\nrate\\n\\nor\\n\\nGPT\\n\\n4.\\n\\nGemini\\n\\nUltra\\n\\nalso\\n\\nexcels\\n\\nin\\n\\ncoding,\\n\\npopular\\n\\nuse\\n\\ncase\\n\\ncurrent\\n\\nLLMs.\\n\\nevaluate\\n\\nthe\\n\\nodel\\n\\non\\n\\nmany\\n\\nconv\\n\\nentional\\n\\nand\\n\\nintern\\n\\nbenchmarks\\n\\nand\\n\\nalso\\n\\nmeasure\\n\\nits\\n\\nperf\\n\\normance\\n\\nas\\n\\npart\\n\\nof\\n\\nmore\\n\\ncomplex\\n\\nreasoning\\n\\nsystems\\n\\nsuch\\n\\nas\\n\\nAlphaCode\\n\\n(see\\n\\nsection\\n\\n5.1.7 on\\n\\ncompl\\n\\nex\\n\\nreaso\\n\\nning\\n\\nsystems).', metadata={'page': 9, 'source': 'GeminiPaper'})]}\n",
            "faithfulness_score: 0.5\n",
            "answer_relevancy_score: 0.9519613977216466\n",
            "context_relevancy_score: 0.0175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FpXeGhD6z6Dm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}